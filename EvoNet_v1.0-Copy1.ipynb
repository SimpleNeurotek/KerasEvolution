{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Conv1D, Conv2D, LSTM, GRU, Flatten, Dropout, Input, Reshape, BatchNormalization\n",
    "from keras.layers import MaxPool1D, MaxPool2D, Embedding, Bidirectional, TimeDistributed, concatenate\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adadelta, Adagrad, Adam, Adamax, Nadam, RMSprop, SGD\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "import seaborn as sns\n",
    "from sklearn.utils.extmath import softmax\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_pool = {\n",
    "        Adadelta: {'learning_rate': [1.0, 0.99, 0.95, 0.9, 0.85, 0.8]}, \n",
    "        Adagrad: {'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001]},\n",
    "        Adam: {'learning_rate': [0.01, 0.005, 0.001, 0.0005, 0.0001]},\n",
    "        Adamax: {'learning_rate': [0.02, 0.005, 0.002, 0.0005, 0.0002]},\n",
    "        Nadam: {'learning_rate': [0.02, 0.005, 0.002, 0.0005, 0.0002]},\n",
    "        RMSprop: {'learning_rate': [0.01, 0.005, 0.001, 0.0005, 0.0001]},\n",
    "        SGD: {'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001], \n",
    "              'nesterov': [True], 'momentum': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]}\n",
    "}\n",
    "\n",
    "LAYERS = {\"Dense\": Dense, \"Conv1D\": Conv1D, \"Conv2D\": Conv2D, \n",
    "          \"LSTM\": LSTM, \"GRU\": GRU, \"Flatten\": Flatten, \n",
    "          \"Dropout\": Dropout, \"Input\": Input, \"Reshape\": Reshape, \n",
    "          \"BatchNormalization\": BatchNormalization, \"MaxPooling1D\": MaxPool1D, \n",
    "          \"MaxPooling2D\": MaxPool2D, \"Embedding\": Embedding, \n",
    "          \"Bidirectional\": Bidirectional, \"TimeDistributed\": TimeDistributed}\n",
    "\n",
    "parameter_pool = {\n",
    "    \"initializers\": [\n",
    "            \"Zeros\",\n",
    "            \"Ones\",\n",
    "            \"RandomNormal\",\n",
    "            \"RandomUniform\",\n",
    "            \"TruncatedNormal\",\n",
    "            \"VarianceScaling\",\n",
    "            \"Orthogonal\",\n",
    "            \"lecun_uniform\",\n",
    "            \"glorot_normal\",\n",
    "            \"glorot_uniform\",\n",
    "            \"he_normal\",\n",
    "            \"lecun_normal\",\n",
    "            \"he_uniform\"\n",
    "        ],\n",
    "    \"activations\": [\n",
    "            \"elu\",\n",
    "            \"relu\",\n",
    "            \"softmax\",\n",
    "            \"selu\",\n",
    "            \"softplus\",\n",
    "            \"softsign\",\n",
    "            \"tanh\",\n",
    "            \"sigmoid\",\n",
    "            \"hard_sigmoid\",\n",
    "            \"exponential\",\n",
    "            \"linear\"\n",
    "        ],\n",
    "    \"regularizers\": [\n",
    "            \"l1\",\n",
    "            \"l2\",\n",
    "            \"l1_l2\"\n",
    "        ],\n",
    "    \n",
    "    \"constraints\": [\n",
    "            \"MaxNorm\",\n",
    "            \"NonNeg\",\n",
    "            \"UnitNorm\",\n",
    "            \"MinMaxNorm\"\n",
    "        ]\n",
    "    \n",
    "}\n",
    "\n",
    "layer_parameters = {\n",
    "    \"Dense\": {\n",
    "                \"units\": [2, 4, 6, 8, 10, 12,14, 16],\n",
    "                \"activation\": parameter_pool[\"activations\"], \n",
    "                \"use_bias\": [False, True], \n",
    "                \"kernel_initializer\": parameter_pool[\"initializers\"], \n",
    "                \"bias_initializer\": parameter_pool[\"initializers\"], \n",
    "                \"kernel_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"bias_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"activity_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"kernel_constraint\": parameter_pool[\"constraints\"], \n",
    "                \"bias_constraint\": parameter_pool[\"constraints\"]\n",
    "            },\n",
    "    \"Conv1D\": {\n",
    "                \"filters\": [2, 4, 6, 8, 10, 12, 14, 16], \n",
    "                \"kernel_size\": [(1,), (2,), (3,), (4,), (5,), (6,), (7,), (8,)], \n",
    "                \"padding\": [\"same\"], \n",
    "                # \"data_format\": [None, \"channels_last\", \"channels_first\"], \n",
    "                \"activation\": parameter_pool[\"activations\"], \n",
    "                \"use_bias\": [True, False], \n",
    "                \"kernel_initializer\": parameter_pool[\"initializers\"], \n",
    "                \"bias_initializer\": parameter_pool[\"initializers\"], \n",
    "                \"kernel_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"bias_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"activity_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"kernel_constraint\": parameter_pool[\"constraints\"], \n",
    "                \"bias_constraint\": parameter_pool[\"constraints\"]\n",
    "            },\n",
    "    \"Conv2D\": {\n",
    "                \"filters\": [2, 4, 6, 8, 10, 12, 14, 16], \n",
    "                \"kernel_size\": [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8)], \n",
    "                # \"padding\": [\"valid\", \"causal\", \"same\"], \n",
    "                # \"data_format\": [None, \"channels_last\", \"channels_first\"], \n",
    "                \"activation\": parameter_pool[\"activations\"], \n",
    "                \"use_bias\": [True, False], \n",
    "                \"kernel_initializer\": parameter_pool[\"initializers\"], \n",
    "                \"bias_initializer\": parameter_pool[\"initializers\"], \n",
    "                \"kernel_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"bias_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"activity_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"kernel_constraint\": parameter_pool[\"constraints\"], \n",
    "                \"bias_constraint\": parameter_pool[\"constraints\"]\n",
    "            },\n",
    "    \"GRU\": {\n",
    "                \"units\": [2, 4, 6, 8, 10, 12, 14, 16], \n",
    "                \"activation\": parameter_pool[\"activations\"], \n",
    "                \"recurrent_activation\": parameter_pool[\"activations\"], \n",
    "                \"use_bias\": [True, False], \n",
    "                \"kernel_initializer\": parameter_pool[\"initializers\"], \n",
    "                \"recurrent_initializer\": parameter_pool[\"initializers\"], \n",
    "                \"bias_initializer\": parameter_pool[\"initializers\"], \n",
    "                \"kernel_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"recurrent_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"bias_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"activity_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"kernel_constraint\": parameter_pool[\"constraints\"], \n",
    "                \"recurrent_constraint\": parameter_pool[\"constraints\"], \n",
    "                \"bias_constraint\": parameter_pool[\"constraints\"], \n",
    "                \"dropout\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "                \"recurrent_dropout\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "                \"implementation\": [1, 2], \n",
    "                \"return_sequences\": [True], \n",
    "                # \"return_state\": [True, False], \n",
    "                \"go_backwards\": [True, False], \n",
    "                # \"stateful\": [True, False], \n",
    "                \"unroll\": [True, False], \n",
    "                \"reset_after\": [True, False]\n",
    "            },\n",
    "    \"LSTM\": {\n",
    "                \"units\": [2, 4, 6, 8, 10, 12, 14, 16], \n",
    "                \"activation\": parameter_pool[\"activations\"], \n",
    "                \"recurrent_activation\": parameter_pool[\"activations\"], \n",
    "                \"use_bias\": [True, False], \n",
    "                \"kernel_initializer\": parameter_pool[\"initializers\"], \n",
    "                \"recurrent_initializer\": parameter_pool[\"initializers\"], \n",
    "                \"bias_initializer\": parameter_pool[\"initializers\"], \n",
    "                \"unit_forget_bias\": [True, False],\n",
    "                \"kernel_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"recurrent_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"bias_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"activity_regularizer\": parameter_pool[\"regularizers\"], \n",
    "                \"kernel_constraint\": parameter_pool[\"constraints\"], \n",
    "                \"recurrent_constraint\": parameter_pool[\"constraints\"], \n",
    "                \"bias_constraint\": parameter_pool[\"constraints\"], \n",
    "                \"dropout\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "                \"recurrent_dropout\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "                \"implementation\": [1, 2], \n",
    "                \"return_sequences\": [True], \n",
    "                # \"return_state\": [True, False], \n",
    "                \"go_backwards\": [True, False], \n",
    "                # \"stateful\": [True, False], \n",
    "                \"unroll\": [True, False], \n",
    "            },\n",
    "    \"Dropout\": {\n",
    "                \"rate\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "            },\n",
    "    \"Flatten\": {\n",
    "                \"data_format\": [None, \"channels_last\", \"channels_first\"]\n",
    "            },\n",
    "    \"MaxPooling1D\": {\n",
    "                \"pool_size\": [2, 3, 4, 5, 6, 7, 8], \n",
    "                # \"padding\": [\"valid\", \"causal\", \"same\"],\n",
    "                # \"data_format\": [None, \"channels_last\", \"channels_first\"]\n",
    "            }, \n",
    "    \"MaxPooling2D\": {\n",
    "                \"pool_size\": [(2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8)], \n",
    "                # \"padding\": [\"valid\", \"causal\", \"same\"],\n",
    "                # \"data_format\": [None, \"channels_last\", \"channels_first\"]\n",
    "            } \n",
    "}\n",
    "\n",
    "def get_random_layer_parameters(layer):\n",
    "            layer_name = re.sub(r'<.+\\'(.+)\\'>', r'\\1', str(layer)).split(\".\")[-1]\n",
    "            random_parameters = {key: choice(value) for key, value in layer_parameters[layer_name].items()}\n",
    "            return layer(**random_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandNet(object):\n",
    "    \n",
    "    def __init__(self, feature_data_shape, label_data_shape,\n",
    "                 num_classes=1,\n",
    "                 get_random_layer_parameters=get_random_layer_parameters,\n",
    "                 optimizer_pool=optimizer_pool,\n",
    "                 layer_types=LAYERS, init_hl=True):\n",
    "        \n",
    "        \"\"\"\n",
    "        Creates a randomly initialized neural net in keras with \n",
    "        functional API Model and is used for initial state for\n",
    "        a modified NEAT-algorithm\n",
    "        \n",
    "        parameters:\n",
    "        - feature_data_shape: tuple, shape of the feature data\n",
    "        - label_data_shape: tuple, shape of the label data \n",
    "                            -> NO one-hot-encoding needed\n",
    "        => easiest way: feature_data / label_data as numpy array \n",
    "           -> use shape attribute\n",
    "        - num_classes: int, number of classes in label data\n",
    "           -> defaults to: 1 -> binary classification\n",
    "        - get_random_layer_parameters: function, randomly initializes layer\n",
    "        - optimizer_pool: dict, parameters for keras optimizers\n",
    "        \"\"\"\n",
    "        \n",
    "        # data configs\n",
    "        self.feature_data_shape = feature_data_shape\n",
    "        self.label_data_shape = label_data_shape\n",
    "        self.feature_shape_length = len(self.feature_data_shape)\n",
    "        self.input_shape = tuple(list(self.feature_data_shape)[1:])\n",
    "        self.output_shape = tuple(list(self.label_data_shape)[1:])\n",
    "        self.num_classes = num_classes\n",
    "        self.layer_names = [str(lt) for lt in layer_types.values()]\n",
    "        self.layer_types = list(layer_types.values())\n",
    "        self.core_layers = [Dense, Conv1D, Conv2D, LSTM, GRU]\n",
    "        self.optimizer_pool = optimizer_pool\n",
    "        self.get_random_layer_parameters = get_random_layer_parameters\n",
    "        self.optimizers = [\"sgd\", \"rmsprop\", \"adadelta\", \"adam\", \n",
    "                           \"adamax\", \"nadam\"]\n",
    "               \n",
    "        # init net\n",
    "        self.input_layer = Input(shape=self.input_shape)\n",
    "        if init_hl:\n",
    "            self.hidden_layers = pd.DataFrame(data={\"parallel_1\": \\\n",
    "                                                    [get_random_layer_parameters(choice(self.core_layers))]})\n",
    "        else:\n",
    "            self.hidden_layers = pd.DataFrame(data={\"parallel_1\": \\\n",
    "                                                    []})\n",
    "        if num_classes is None or 1 <= num_classes <= 2:\n",
    "            self.output_layer = Dense(1)\n",
    "        else:\n",
    "            self.output_layer = Dense(num_classes)\n",
    "        self.output_tensors = []\n",
    "        self.insertion_count = 0\n",
    "        self.deletion_count = 0\n",
    "        self.mutation_count = 0\n",
    "        self.input_tensor = self.input_layer\n",
    "        self.output_tensor = None\n",
    "        \n",
    "    def initialize_random_layer(self, layers=[Dense, Conv1D, Conv2D, LSTM, GRU]):\n",
    "        return self.get_random_layer_parameters(choice(layers))\n",
    "        \n",
    "    def insertion(self, layer, axis=0):\n",
    "        \n",
    "        cols = self.hidden_layers.columns\n",
    "        df_length = len(self.hidden_layers)\n",
    "        if axis == 0:\n",
    "            # vertical insertion\n",
    "            rand_col = choice(cols)\n",
    "            if isinstance(layer, tuple(self.core_layers)):\n",
    "                self.hidden_layers.loc[df_length, rand_col] = layer\n",
    "            else:\n",
    "                self.hidden_layers.loc[df_length, rand_col] = self.get_random_layer_parameters(layer)\n",
    "            \n",
    "        elif axis == 1:\n",
    "            # horizontal insertion\n",
    "            parallel_count = re.search(r'_(\\d+)', cols[-1])\n",
    "            if parallel_count:\n",
    "                parallel_count = int(parallel_count.group(1))\n",
    "            else:\n",
    "                raise TypeError(\"No column number found in column string.\")\n",
    "            \n",
    "            if isinstance(layer, tuple(self.core_layers)):\n",
    "                self.hidden_layers[\"parallel_{}\".format(parallel_count + 1)] = \\\n",
    "                [layer] + ([np.nan] * (df_length - 1))\n",
    "            else:\n",
    "                self.hidden_layers[\"parallel_{}\".format(parallel_count + 1)] = \\\n",
    "                [self.get_random_layer_parameters(layer)] + ([np.nan] * (df_length - 1))            \n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Axis-Error: please check the value of the axis parameter.\")\n",
    "            \n",
    "    def modify(self, layer, input_tensor):\n",
    "        # insert some modification layers like MaxPooling etc.\n",
    "        rand_num = np.random.uniform(0, 1)\n",
    "        layer_name = str(type(layer))\n",
    "        \n",
    "        # some maxpooling\n",
    "        if layer_name == str(Conv1D):\n",
    "            output_tensor = self.get_random_layer_parameters(MaxPool1D)(input_tensor)\n",
    "        elif layer_name == str(Conv2D) and len(input_tensor.shape) == 3:\n",
    "            output_tensor = self.get_random_layer_parameters(MaxPool1D)(input_tensor)\n",
    "        elif layer_name == str(Conv2D) and len(input_tensor.shape) > 3:\n",
    "            output_tensor = self.get_random_layer_parameters(MaxPool2D)(input_tensor)\n",
    "        else:\n",
    "            output_tensor = input_tensor\n",
    "            \n",
    "        # some Dropout layer\n",
    "        if rand_num <= 0.5:\n",
    "            output_tensor = self.get_random_layer_parameters(Dropout)(output_tensor)\n",
    "        # some BatchNormalization layer\n",
    "        elif 0.5 < rand_num <= 0.75:\n",
    "            output_tensor = BatchNormalization()(output_tensor)\n",
    "            \n",
    "        return output_tensor\n",
    "    \n",
    "    def bidirectional(self, recurrent_layer):\n",
    "        # make a bidirectional connection to a recurrent layer\n",
    "        return Bidirectional(recurrent_layer)\n",
    "    \n",
    "    def timedistribute(self, dense_layer):\n",
    "        # make a timedistributed connection to a dense layer\n",
    "        return TimeDistributed(dense_layer)\n",
    "    \n",
    "    def send_tensor_and_reshape(self, modify=True):\n",
    "        # walk through the hidden_layers dataframe and \n",
    "        # connect the layers with the input tensor and\n",
    "        # insert reshape layer if necessary\n",
    "        output_tensors = []\n",
    "        for parallel in self.hidden_layers.columns:\n",
    "            tensor = None\n",
    "            for i, layer in enumerate(self.hidden_layers[parallel].values.tolist()):\n",
    "                if str(layer) == 'nan':\n",
    "                    continue\n",
    "                if i == 0:\n",
    "                    tensor = self.inject_reshape(layer, self.input_layer)\n",
    "                else:\n",
    "                    tensor = self.inject_reshape(layer, tensor)\n",
    "                # add some modification layers\n",
    "                if modify:\n",
    "                    if np.random.uniform(0, 1) <= 0.5:\n",
    "                        tensor = self.modify(layer, tensor)\n",
    "            if tensor is not None:\n",
    "                output_tensors.append(tensor)\n",
    "        self.output_tensors = output_tensors\n",
    "        \n",
    "    def concat_output_tensors(self):\n",
    "        # concatenate the output tensors to one \n",
    "        # final tensor for last dense layer\n",
    "        reshaped_tensors = []\n",
    "        for ot in self.output_tensors:\n",
    "            try:\n",
    "                reshaped_tensors.append(Reshape((-1,))(ot))\n",
    "            except:\n",
    "                continue\n",
    "        if len(reshaped_tensors) >= 2:\n",
    "            return concatenate(reshaped_tensors)\n",
    "        elif len(reshaped_tensors) == 1:\n",
    "            return reshaped_tensors[0]\n",
    "        else:\n",
    "            return reshaped_tensors\n",
    "                    \n",
    "    def inject_reshape(self, layer, input_tensor):\n",
    "        layer_type = str(type(layer))\n",
    "        tensor_shape = input_tensor.shape\n",
    "        tensor_shape_length = len(tensor_shape)\n",
    "        if layer_type == str(Dense):\n",
    "            return layer(input_tensor)\n",
    "        elif layer_type in [str(LSTM), str(GRU), str(Conv1D)]:\n",
    "            # (batch_size, features, time_steps)\n",
    "            if tensor_shape_length == 3:\n",
    "                return layer(input_tensor)\n",
    "            elif tensor_shape_length == 2:\n",
    "                reshaped = Reshape((tensor_shape[1], 1))(input_tensor)\n",
    "                return layer(reshaped)\n",
    "            elif tensor_shape_length > 3:\n",
    "                reshaped = Reshape((tensor_shape[1], -1))\n",
    "                return layer(reshaped)\n",
    "            else:\n",
    "                raise ValueError(\"The Input tensor must have more than 2 dimensions for recurrent layers.\"\\\n",
    "                                 \"Given:  {}.\".format(tensor_shape))\n",
    "        elif layer_type == str(Conv2D):\n",
    "            if tensor_shape_length == 2:\n",
    "                new_layer = self.get_random_layer_parameters(Conv1D)\n",
    "                reshaped = Reshape((tensor_shape[1], 1))(input_tensor)\n",
    "                print(\"2 dim to Conv1D: \" + str(reshaped.shape))\n",
    "                return new_layer(reshaped)\n",
    "            elif tensor_shape_length == 3:\n",
    "                reshaped = Reshape((tensor_shape[1], tensor_shape[2], 1))(input_tensor)\n",
    "                print(\"3 dim to 4 dim: \" + str(reshaped.shape))\n",
    "                return layer(reshaped)\n",
    "            elif tensor_shape_length >= 4:\n",
    "                reshaped = Reshape((tensor_shape[1], tensor_shape[2], -1))(input_tensor)\n",
    "                return layer(reshaped)\n",
    "            else:\n",
    "                raise ValueError(\"The Input tensor must have more than 3 dimensions for Conv2D layers.\"\\\n",
    "                                 \"Given:  {}.\".format(tensor_shape))\n",
    "                    \n",
    "    \n",
    "    def create_model(self, print_summary=True):\n",
    "        # randomly pick optimizer\n",
    "        opti = choice(list(self.optimizer_pool.keys()))\n",
    "        opti = opti(**{key: choice(value) for key, value in self.optimizer_pool[opti].items()})\n",
    "        \n",
    "        # connect net parts\n",
    "        self.send_tensor_and_reshape()\n",
    "        self.output_tensor = self.output_layer(self.concat_output_tensors())\n",
    "        \n",
    "        # initialize model\n",
    "        model = Model(inputs=self.input_tensor, outputs=self.output_tensor)\n",
    "        if print_summary:\n",
    "            model.summary()\n",
    "        if self.num_classes > 2:\n",
    "            model.compile(optimizer=opti, \n",
    "                          loss=\"sparse_categorical_crossentropy\", \n",
    "                          metrics=[\"sparse_categorical_accuracy\"])\n",
    "        elif self.num_classes in [1, 2]:\n",
    "            model.compile(optimizer=opti, \n",
    "                          loss=\"binary_crossentropy\", \n",
    "                          metrics=[\"binary_accuracy\"])\n",
    "        else:\n",
    "            raise ValueError(\"Some Error in choosing the loss function ...\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_data = load_breast_cancer()\n",
    "bc_features = bc_data['data']\n",
    "bc_labels = bc_data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(bc_features, bc_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "randnet = RandNet(feature_data_shape=X_train.shape, label_data_shape=y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "randnet.insertion(layer=choice(randnet.core_layers), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "randnet.insertion(layer=choice(randnet.core_layers), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parallel_1</th>\n",
       "      <th>parallel_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0...</td>\n",
       "      <td>&lt;keras.layers.convolutional.Conv1D object at 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;keras.layers.recurrent.LSTM object at 0x7f0d3...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          parallel_1  \\\n",
       "0  <keras.layers.convolutional.Conv2D object at 0...   \n",
       "1  <keras.layers.recurrent.LSTM object at 0x7f0d3...   \n",
       "\n",
       "                                          parallel_2  \n",
       "0  <keras.layers.convolutional.Conv1D object at 0...  \n",
       "1                                                NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randnet.hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 dim to Conv1D: (None, 30, 1)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 30, 1)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 30, 6)        12          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 30, 1)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 30, 16)       1408        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 30, 4)        20          reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 480)          0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 120)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 600)          0           reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            601         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,041\n",
      "Trainable params: 2,041\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = randnet.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/10\n",
      "455/455 [==============================] - 2s 4ms/step - loss: 3247.7070 - binary_accuracy: 0.3890 - val_loss: 25.1402 - val_binary_accuracy: 0.8684\n",
      "Epoch 2/10\n",
      "455/455 [==============================] - 0s 359us/step - loss: 16804.3765 - binary_accuracy: 0.4659 - val_loss: 26.5064 - val_binary_accuracy: 0.6228\n",
      "Epoch 3/10\n",
      "455/455 [==============================] - 0s 369us/step - loss: 15325.9287 - binary_accuracy: 0.4681 - val_loss: 32.5796 - val_binary_accuracy: 0.6228\n",
      "Epoch 4/10\n",
      "455/455 [==============================] - 0s 364us/step - loss: 5013.3030 - binary_accuracy: 0.4681 - val_loss: 37.6340 - val_binary_accuracy: 0.0351\n",
      "Epoch 5/10\n",
      "455/455 [==============================] - 0s 365us/step - loss: 185360.0526 - binary_accuracy: 0.4022 - val_loss: 31.5003 - val_binary_accuracy: 0.6228\n",
      "Epoch 6/10\n",
      "455/455 [==============================] - 0s 354us/step - loss: 820.7546 - binary_accuracy: 0.4593 - val_loss: 24.0272 - val_binary_accuracy: 0.8947\n",
      "Epoch 7/10\n",
      "455/455 [==============================] - 0s 355us/step - loss: 1525.1132 - binary_accuracy: 0.4615 - val_loss: 24.6693 - val_binary_accuracy: 0.8772\n",
      "Epoch 8/10\n",
      "455/455 [==============================] - 0s 360us/step - loss: 5663.7445 - binary_accuracy: 0.5187 - val_loss: 23.7789 - val_binary_accuracy: 0.8947\n",
      "Epoch 9/10\n",
      "455/455 [==============================] - 0s 367us/step - loss: 10243.9289 - binary_accuracy: 0.5582 - val_loss: 26.4454 - val_binary_accuracy: 0.6228\n",
      "Epoch 10/10\n",
      "455/455 [==============================] - 0s 359us/step - loss: 1911.9729 - binary_accuracy: 0.4989 - val_loss: 24.2298 - val_binary_accuracy: 0.8509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f0c900df750>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=int(round(X_train.shape[0] * 0.05)), epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del randnet\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvoNet(object):\n",
    "    \n",
    "    def __init__(self, feature_data, label_data, start_population=10, \n",
    "                 num_classes=1, threshold=0.99, max_generations=10, layer_dict=LAYERS):\n",
    "        \n",
    "        self.breeding_pool = {}\n",
    "        self.feature_data = np.array(feature_data)\n",
    "        self.label_data = np.array(label_data)\n",
    "        self.start_population = start_population\n",
    "        self.num_classes = num_classes\n",
    "        self.data_amount = self.feature_data.shape[0]\n",
    "        self.gen_count = 1\n",
    "        self.offspring_count = self.start_population - 2\n",
    "        self.max_generations = max_generations\n",
    "        self.threshold = threshold\n",
    "        self.layer_dict = layer_dict\n",
    "        self.core_layers = [Dense, Conv1D, Conv2D, LSTM, GRU]\n",
    "        # batch_size depending on amount of data\n",
    "        self.batch_size = round(0.05 * self.data_amount)\n",
    "            \n",
    "        # train and test data split\n",
    "        if self.data_amount < 1000:\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.feature_data, self.label_data, test_size=0.33, random_state=42)\n",
    "        else:\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.feature_data, self.label_data, test_size=0.2, random_state=42)\n",
    "        \n",
    "    def generate_initial_generation(self):\n",
    "        key = \"gen_1\"\n",
    "        first_population = []\n",
    "        for i in range(self.start_population):\n",
    "            # generate randnets for modelling\n",
    "            randnet = RandNet(self.feature_data.shape, self.label_data.shape, num_classes=self.num_classes)\n",
    "            first_population.append({\"model\": randnet.create_model(), \"checkpoint\": None, \"train_history\": None})\n",
    "                    \n",
    "        self.breeding_pool[key] = first_population\n",
    "    \n",
    "    def mutate(self):\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Train each model over 10 epochs and choose best \n",
    "        accuracy for ranking.\n",
    "        Appends top 2 tuple at gen value (population) in dict\n",
    "        \"\"\"\n",
    "        directory = \".model_results/\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        for gen, population in self.breeding_pool.items():\n",
    "            if population[0][\"checkpoint\"] is None:\n",
    "                for individuum in population:\n",
    "                    checkpoint = ModelCheckpoint(directory + \"{}_{}.h5\".format(gen, individuum[\"model\"].name), \n",
    "                                                 verbose=False, monitor=individuum[\"model\"]._compile_metrics[0],\n",
    "                                                 save_best_only=True, mode='max')\n",
    "                    individuum[\"train_history\"] = individuum[\"model\"].fit(self.X_train, self.y_train, epochs=10, \n",
    "                                                                          validation_data=(self.X_test, self.y_test), \n",
    "                                                                          callbacks=[checkpoint], verbose=False)\n",
    "                    individuum[\"checkpoint\"] = checkpoint\n",
    "                best_epochs = sorted([individuum[\"checkpoint\"].best for individuum in population], reverse=True)\n",
    "                top_2 = tuple(sorted([individuum for individuum in population if individuum[\"checkpoint\"].best in best_epochs[:2]], key=lambda x: x[\"checkpoint\"].best, reverse=True))\n",
    "                self.breeding_pool[gen].append(top_2)\n",
    "    \n",
    "    def mate(self):\n",
    "        previous_key = \"gen_{}\".format(self.gen_count)\n",
    "        previous_gen = self.breeding_pool[previous_key]\n",
    "        new_key = \"gen_{}\".format(self.gen_count + 1)\n",
    "        top_2 = self.breeding_pool[previous_key][-1]\n",
    "        male, female = (top_2[0][\"model\"], top_2[1][\"model\"])\n",
    "        male_hidden_layers = self.get_hidden_layers(male)\n",
    "        female_hidden_layers = self.get_hidden_layers(female)\n",
    "        \n",
    "        if self.gen_count == 1:\n",
    "            \n",
    "            rand_num_1 = np.random.uniform(0, 1)\n",
    "            # offspring\n",
    "            offsprings = []\n",
    "            for j in tqdm_notebook(range(self.offspring_count)):\n",
    "                for z in range(5):\n",
    "                    try:\n",
    "                        randnet = RandNet(self.feature_data.shape, self.label_data.shape, \n",
    "                                          num_classes=self.num_classes, init_hl=True)\n",
    "\n",
    "                        if rand_num_1 <= 0.5:\n",
    "                            rand_num_2 = np.random.uniform(0, 1)\n",
    "                            # insert male hidden layers\n",
    "                            self.insert_hidden_layers(randnet, male_hidden_layers)\n",
    "                            # insert female hidden layers\n",
    "                            if rand_num_2 <= 0.5:\n",
    "                                self.insert_hidden_layers(randnet, female_hidden_layers)\n",
    "                            else:\n",
    "                                self.insert_hidden_layers(randnet, female_hidden_layers, axis=1)\n",
    "                            offsprings.append({\"model\": randnet.create_model(), \"checkpoint\": None, \"train_history\": None})\n",
    "                        else:\n",
    "                            rand_num_2 = np.random.uniform(0, 1)\n",
    "                            # insert male hidden layers\n",
    "                            self.insert_hidden_layers(randnet, female_hidden_layers)\n",
    "                            # insert female hidden layers\n",
    "                            if rand_num_2 <= 0.5:\n",
    "                                self.insert_hidden_layers(randnet, male_hidden_layers)\n",
    "                            else:\n",
    "                                self.insert_hidden_layers(randnet, male_hidden_layers, axis=1)\n",
    "                            offsprings.append({\"model\": randnet.create_model(), \"checkpoint\": None, \"train_history\": None})\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                # adding offspring to new generation in breeding_pool \n",
    "                self.breeding_pool[new_key] = offsprings\n",
    "        else:\n",
    "            # define some layer mating and crossing over\n",
    "            pass\n",
    "        \n",
    "        self.gen_count += 1\n",
    "        \n",
    "    def insert_hidden_layers(self, randnet, hidden_layers, axis=0, modify=False):\n",
    "        for hl in hidden_layers:\n",
    "            randnet.insertion(hl, axis)\n",
    "            \n",
    "    # randnet as parameter instead of model    \n",
    "    def get_hidden_layers(self, model):\n",
    "        model_layers = model.get_config()[\"layers\"]\n",
    "        model_hidden_layers = model_layers[1:-1]\n",
    "        recovered_layers = []\n",
    "        for hidden_layer in model_hidden_layers:\n",
    "            new_layer = self.layer_dict[hidden_layer[\"class_name\"]].from_config(hidden_layer[\"config\"])\n",
    "            if str(type(new_layer)) in [str(cl) for cl in self.core_layers]:\n",
    "                recovered_layers.append(new_layer)\n",
    "            \n",
    "        return recovered_layers\n",
    "        \n",
    "    def layer_class_to_class_name(layer_class):\n",
    "        return re.sub(r'<.+\\'(.+)\\'>', r'\\1', str(layer_class))\n",
    "    \n",
    "    def select(self):\n",
    "        gen_key = \"gen_{}\".format(self.gen_count)\n",
    "        actual_gen = self.breeding_pool[gen_key]\n",
    "        initial_gen_length = len(self.breeding_pool[gen_key])\n",
    "        for c in range(initial_gen_length):\n",
    "            if c == initial_gen_length - 1:\n",
    "                break\n",
    "            else:\n",
    "                del self.breeding_pool[gen_key][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "evonet = EvoNet(bc_features, bc_labels, start_population=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "reshape_69 (Reshape)         (None, 30, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 30, 10)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 5, 10)             0         \n",
      "_________________________________________________________________\n",
      "reshape_70 (Reshape)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 91\n",
      "Trainable params: 91\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2 dim to Conv1D: (None, 30, 1)\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "reshape_71 (Reshape)         (None, 30, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 30, 6)             12        \n",
      "_________________________________________________________________\n",
      "reshape_72 (Reshape)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 181       \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2 dim to Conv1D: (None, 30, 1)\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_42 (InputLayer)        (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "reshape_73 (Reshape)         (None, 30, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 30, 4)             28        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 15, 4)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 15, 4)             16        \n",
      "_________________________________________________________________\n",
      "reshape_74 (Reshape)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 105\n",
      "Trainable params: 97\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "reshape_75 (Reshape)         (None, 30, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 30, 16)            128       \n",
      "_________________________________________________________________\n",
      "reshape_76 (Reshape)         (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 481       \n",
      "=================================================================\n",
      "Total params: 609\n",
      "Trainable params: 609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2 dim to Conv1D: (None, 30, 1)\n",
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "reshape_77 (Reshape)         (None, 30, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 30, 4)             8         \n",
      "_________________________________________________________________\n",
      "reshape_78 (Reshape)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 121       \n",
      "=================================================================\n",
      "Total params: 129\n",
      "Trainable params: 129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "evonet.generate_initial_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "evonet.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8346457"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evonet.breeding_pool[\"gen_1\"][-1][0][\"checkpoint\"].best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3db9c4b49d34b87aeb5a961c1966cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_39\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_45 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_79 (Reshape)            (None, 30, 1)        0           input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 30, 4)        80          reshape_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_80 (Reshape)            (None, 30, 1)        0           input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 30, 6)        30          lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 30, 4)        28          reshape_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_81 (Reshape)            (None, 180)          0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_82 (Reshape)            (None, 120)          0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 300)          0           reshape_81[0][0]                 \n",
      "                                                                 reshape_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 1)            301         concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 439\n",
      "Trainable params: 439\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "2 dim to Conv1D: (None, 30, 1)\n",
      "2 dim to Conv1D: (None, 30, 1)\n",
      "2 dim to Conv1D: (None, 30, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evonet.mate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gen_1': [{'model': <keras.engine.training.Model at 0x7f0c55422950>,\n",
       "   'checkpoint': <keras.callbacks.callbacks.ModelCheckpoint at 0x7f0c54ef18d0>,\n",
       "   'train_history': <keras.callbacks.callbacks.History at 0x7f0c5485ae10>},\n",
       "  {'model': <keras.engine.training.Model at 0x7f0c553c3290>,\n",
       "   'checkpoint': <keras.callbacks.callbacks.ModelCheckpoint at 0x7f0c548b7510>,\n",
       "   'train_history': <keras.callbacks.callbacks.History at 0x7f0c541e7f90>},\n",
       "  {'model': <keras.engine.training.Model at 0x7f0c552b5290>,\n",
       "   'checkpoint': <keras.callbacks.callbacks.ModelCheckpoint at 0x7f0c5427b250>,\n",
       "   'train_history': <keras.callbacks.callbacks.History at 0x7f0c534e6bd0>},\n",
       "  {'model': <keras.engine.training.Model at 0x7f0c550d9a10>,\n",
       "   'checkpoint': <keras.callbacks.callbacks.ModelCheckpoint at 0x7f0c538a8cd0>,\n",
       "   'train_history': <keras.callbacks.callbacks.History at 0x7f0c538963d0>},\n",
       "  {'model': <keras.engine.training.Model at 0x7f0c54fcfa50>,\n",
       "   'checkpoint': <keras.callbacks.callbacks.ModelCheckpoint at 0x7f0c52eb9a90>,\n",
       "   'train_history': <keras.callbacks.callbacks.History at 0x7f0c52752cd0>},\n",
       "  ({'model': <keras.engine.training.Model at 0x7f0c552b5290>,\n",
       "    'checkpoint': <keras.callbacks.callbacks.ModelCheckpoint at 0x7f0c5427b250>,\n",
       "    'train_history': <keras.callbacks.callbacks.History at 0x7f0c534e6bd0>},\n",
       "   {'model': <keras.engine.training.Model at 0x7f0c553c3290>,\n",
       "    'checkpoint': <keras.callbacks.callbacks.ModelCheckpoint at 0x7f0c548b7510>,\n",
       "    'train_history': <keras.callbacks.callbacks.History at 0x7f0c541e7f90>})],\n",
       " 'gen_2': [{'model': <keras.engine.training.Model at 0x7f0c528dd310>,\n",
       "   'checkpoint': None,\n",
       "   'train_history': None}]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evonet.breeding_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evonet.select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del evonet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
